{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "confronto.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d--cDvf5cauR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186c9ee2-53d7-4ab2-e2ff-14475add8429"
      },
      "source": [
        "!pip -q install tensorflow==\"2.4\"\n",
        "!pip install -q --use-deprecated=legacy-resolver tflite-model-maker\n",
        "!pip install -q pycocotools"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 394.7 MB 18 kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 37.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 38.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 31.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 591 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 28.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 43.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 26.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 840 kB 47.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 213 kB 48.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 49.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 87 kB 6.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 103 kB 41.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 40.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 42.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 207 kB 42.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 55.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 6.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 37.1 MB 42 kB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA0Rk6PPcdRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f349bd1f-40e8-4ebf-934c-d8e270a4d72e"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import object_detector\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "print(tf.__version__)\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.ERROR)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZbbGAfDeJI0"
      },
      "source": [
        "!curl -L \"https://app.roboflow.com/ds/MRtJOCvWpY?key=v5dj2YEsFa\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hdlnkuqnkdw"
      },
      "source": [
        "!mkdir /content/test/images\n",
        "!mkdir /content/test/annotations\n",
        "!mkdir /content/train/images\n",
        "!mkdir /content/train/annotations\n",
        "!mkdir /content/valid/images\n",
        "!mkdir /content/valid/annotations\n",
        "!mv /content/test/*.jpg /content/test/images\n",
        "!mv /content/test/*.xml /content/test/annotations\n",
        "!mv /content/train/*.jpg /content/train/images\n",
        "!mv /content/train/*.xml /content/train/annotations\n",
        "!mv /content/valid/*.jpg /content/valid/images\n",
        "!mv /content/valid/*.xml /content/valid/annotations"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWa7AtSZeMBZ"
      },
      "source": [
        "test_data = object_detector.DataLoader.from_pascal_voc(\n",
        "    \"/content/test/images\",\n",
        "    \"/content/test/annotations\",\n",
        "    label_map={1: \"masked\", 2: \"unmasked\"}) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVTi64brE7ck"
      },
      "source": [
        "import cv2\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "model_path = 'detect.tflite'\n",
        "\n",
        "# Load the labels into a list\n",
        "#classes = ['???'] * model.model_spec.config.num_classes\n",
        "classes = ['???'] * 2\n",
        "##label_map = model.model_spec.config.label_map\n",
        "#for label_id, label_name in label_map.as_dict().items():\n",
        "#  classes[label_id-1] = label_name\n",
        "\n",
        "classes[0] = 'Masked'\n",
        "classes[1] = 'Unmasked'\n",
        "# Define a list of colors for visualization\n",
        "# Define a list of colors for visualization\n",
        "COLORS = np.random.randint(0, 255, size=(len(classes), 3), dtype=np.uint8)\n",
        "\n",
        "def preprocess_image(image_path, input_size):\n",
        "  \"\"\"Preprocess the input image to feed to the TFLite model\"\"\"\n",
        "  img = tf.io.read_file(image_path)\n",
        "  img = tf.io.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, tf.uint8)\n",
        "  original_image = img\n",
        "  resized_img = tf.image.resize(img, input_size)\n",
        "  resized_img = resized_img[tf.newaxis, :]\n",
        "  return resized_img, original_image\n",
        "\n",
        "\n",
        "def set_input_tensor(interpreter, image):\n",
        "  \"\"\"Set the input tensor.\"\"\"\n",
        "  tensor_index = interpreter.get_input_details()[0]['index']\n",
        "  input_tensor = interpreter.tensor(tensor_index)()[0]\n",
        "  input_tensor[:, :] = image\n",
        "\n",
        "\n",
        "def get_output_tensor(interpreter, index):\n",
        "  \"\"\"Retur the output tensor at the given index.\"\"\"\n",
        "  output_details = interpreter.get_output_details()[index]\n",
        "  tensor = np.squeeze(interpreter.get_tensor(output_details['index']))\n",
        "  return tensor\n",
        "\n",
        "\n",
        "def detect_objects(interpreter, image, threshold):\n",
        "  \"\"\"Returns a list of detection results, each a dictionary of object info.\"\"\"\n",
        "  # Feed the input image to the model\n",
        "  set_input_tensor(interpreter, image)\n",
        "  interpreter.invoke()\n",
        "\n",
        "  # Get all outputs from the model\n",
        "  boxes = get_output_tensor(interpreter, 0)\n",
        "  classes = get_output_tensor(interpreter, 1)\n",
        "  scores = get_output_tensor(interpreter, 2)\n",
        "  count = int(get_output_tensor(interpreter, 3))\n",
        "\n",
        "  results = []\n",
        "  for i in range(count):\n",
        "    if scores[i] >= threshold:\n",
        "      result = {\n",
        "        'bounding_box': boxes[i],\n",
        "        'class_id': classes[i],\n",
        "        'score': scores[i]\n",
        "      }\n",
        "      results.append(result)\n",
        "  return results\n",
        "\n",
        "\n",
        "def run_odt_and_draw_results(image_path, interpreter, threshold=0.5):\n",
        "  \"\"\"Run object detection on the input image and draw the detection results\"\"\"\n",
        "  # Load the input shape required by the model\n",
        "  _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']\n",
        "\n",
        "  # Load the input image and preprocess it\n",
        "  preprocessed_image, original_image = preprocess_image(\n",
        "      image_path,\n",
        "      (input_height, input_width)\n",
        "    )\n",
        "\n",
        "  # Run object detection on the input image\n",
        "  results = detect_objects(interpreter, preprocessed_image, threshold=threshold)\n",
        "\n",
        "  # Plot the detection results on the input image\n",
        "  original_image_np = original_image.numpy().astype(np.uint8)\n",
        "  bbC = []\n",
        "  scoreArr = []\n",
        "  classLabels = []\n",
        "  for obj in results:\n",
        "    bb=[]\n",
        "    # Convert the object bounding box from relative coordinates to absolute\n",
        "    # coordinates based on the original image resolution\n",
        "    ymin, xmin, ymax, xmax = obj['bounding_box']\n",
        "    xmin = int(xmin * original_image_np.shape[1])\n",
        "    xmax = int(xmax * original_image_np.shape[1])\n",
        "    ymin = int(ymin * original_image_np.shape[0])\n",
        "    ymax = int(ymax * original_image_np.shape[0])\n",
        "\n",
        "    # Find the class index of the current object\n",
        "    class_id = int(obj['class_id'])\n",
        "    bb.append(xmin)\n",
        "    bb.append(xmax)\n",
        "    bb.append(ymin)\n",
        "    bb.append(ymax)\n",
        "\n",
        "    bbC.append(bb)\n",
        "    scoreArr.append(obj['score'])\n",
        "    classLabels.append(int(obj['class_id']))\n",
        "    # Draw the bounding box and label on the image\n",
        "    color = [int(c) for c in COLORS[class_id]]\n",
        "    cv2.rectangle(original_image_np, (xmin, ymin), (xmax, ymax), color, 2)\n",
        "    # Make adjustments to make the label visible for all objects\n",
        "    y = ymin - 15 if ymin - 15 > 15 else ymin + 15\n",
        "    label = \"{}: {:.0f}%\".format(classes[class_id], obj['score'] * 100)\n",
        "    cv2.putText(original_image_np, label, (xmin, y),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "  # Return the final image\n",
        "  original_uint8 = original_image_np.astype(np.uint8)\n",
        "  return original_uint8,bbC,scoreArr,classLabels"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p19TT_EZcSHi"
      },
      "source": [
        "DETECTION_THRESHOLD = 0.3\n",
        "\n",
        "TEMP_FILE = '/content/test/images/real_01074_jpg.rf.e7ddcf096eb7f357fff020a74b479c5a.jpg'\n",
        "\n",
        "#!wget -q -O $TEMP_FILE $INPUT_IMAGE_URL\n",
        "im = Image.open(TEMP_FILE)\n",
        "#im.thumbnail((512, 512), Image.ANTIALIAS)\n",
        "#im.save(TEMP_FILE, 'JPG')\n",
        "\n",
        "# Load the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Run inference and draw detection result on the local copy of the original file\n",
        "detection_result_image,a,b,c = run_odt_and_draw_results(\n",
        "    TEMP_FILE,\n",
        "    interpreter,\n",
        "    threshold=DETECTION_THRESHOLD\n",
        ")\n",
        "\n",
        "# Show the detection result\n",
        "Image.fromarray(detection_result_image)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v-bt56WFZrz"
      },
      "source": [
        "# Funzione utilizzata per il calcolo dell'Intersection over Union (IoU)\n",
        "def compute_iou(g_xmin,g_xmax,g_ymin,g_ymax, d_xmin,d_xmax,d_ymin,d_ymax):\n",
        "   \n",
        "    \n",
        "    xa = max(g_xmin, d_xmin)\n",
        "    ya = max(g_ymin, d_ymin)\n",
        "    xb = min(g_xmax, d_xmax)\n",
        "    yb = min(g_ymax, d_ymax)\n",
        "\n",
        "    intersection = max(0, xb - xa + 1) * max(0, yb - ya + 1)\n",
        "\n",
        "    boxAArea = (g_xmax - g_xmin + 1) * (g_ymax - g_ymin + 1)\n",
        "    boxBArea = (d_xmax - d_xmin + 1) * (d_ymax - d_ymin + 1)\n",
        "\n",
        "    return intersection / float(boxAArea + boxBArea - intersection)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fV1WHEWSONI"
      },
      "source": [
        "# 0 ---> masked\n",
        "# 1 ---> unmasked\n",
        "# GROUNDTRUTH_BOX rappresentano i valori veri dei rettangoli di delimitazione\n",
        "# label_truth contiene le classi delle immagini\n",
        "groundtruth_box = [[104,262,40,368],[162,370,55,244],[49,348,34,365],\n",
        "                   [172,346,33,381],[204,307,48,264],[56,352,29,327],[140,270,67,285],\n",
        "                   [86,198,87,253],[200,378,75,252],[54,311,93,324],\n",
        "                   [107,279,54,376],[10,278,91,341],[53,322,44,403],\n",
        "                   [97,351,43,362],[68,325,96,387],[118,301,58,316],\n",
        "                   [70,332,30,319],[106,274,46,298],[127,281,41,247],\n",
        "                   [148,347,68,317],[97,322,23,310],[1,296,17,249],[108,326,50,350],\n",
        "                   [157,302,55,307],[154,257,32,276],[81,224,94,264],[140,273,39,300],\n",
        "                   [95,251,103,347],[31,371,33,416],[21,370,12,385],\n",
        "                   [113,351,26,346],[64,363,28,288],[21,286,13,276],\n",
        "                   [119,318,28,264],[66,373,16,380],[2,241,23,211],\n",
        "                   [131,340,18,317],[101,308,19,246],[63,416,15,301],\n",
        "                   [48,323,26,366],[33,319,65,416],[112,266,71,365],\n",
        "                   [29,309,13,263],[56,366,23,369],[67,364,19,386],\n",
        "                   [56,360,20,383],[100,307,35,355],[54,271,58,291],\n",
        "                   [88,294,59,416],[8,315,22,416],[9,377,23,416],\n",
        "                   [23,366,44,411],[13,388,47,408],[38,338,37,416],\n",
        "                   [47,339,23,384],[79,328,39,397],[42,330,37,416],\n",
        "                   [26,361,34,376],[48,337,48,401],[42,370,55,390],\n",
        "                   [24,394,16,415],[23,378,51,400],[73,355,42,397],\n",
        "                   [50,365,55,408],[35,342,36,426],[11,367,39,403],\n",
        "                   [40,398,48,403],[42,334,39,402],[28,352,44,412],\n",
        "                   [47,345,6,375],[49,353,29,407],[12,358,19,410],\n",
        "                   [47,386,17,417],[54,340,56,406],[30,345,38,399],\n",
        "                   [27,335,65,400],[61,384,55,413],[49,357,45,406],\n",
        "                   [68,342,48,403],[51,321,78,396],[43,333,38,416],\n",
        "                   [19,335,38,416],[44,331,69,395],[43,391,62,402],\n",
        "                   [51,364,30,387],[14,362,32,416],[34,351,39,404],\n",
        "                   [37,341,34,391],[26,393,48,387],[29,388,34,408],\n",
        "                   [44,328,31,389],[38,365,17,387],[37,364,37,400],\n",
        "                   [61,361,29,388],[37,346,35,410],[30,346,51,393],\n",
        "                   [40,368,28,381],[52,389,30,416],[26,340,39,416],\n",
        "                   [9,416,28,417]]\n",
        "label_truth = [0,0,0,0,0,0,0,0,0,0,\n",
        "               0,0,0,0,0,0,0,0,0,0,\n",
        "               0,0,0,0,0,0,0,0,0,0,\n",
        "               0,0,0,0,0,0,0,0,0,0,\n",
        "               0,0,0,0,0,0,0,0,0,0,\n",
        "               1,1,1,1,1,1,1,1,1,1,\n",
        "               1,1,1,1,1,1,1,1,1,1,\n",
        "               1,1,1,1,1,1,1,1,1,1,\n",
        "               1,1,1,1,1,1,1,1,1,1,\n",
        "               1,1,1,1,1,1,1,1,1,1\n",
        "               ]\n",
        "\n"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRCxZ01TNesU"
      },
      "source": [
        "# detection box trattiene le predizioni dei rettangolo\n",
        "# scores rappresenta i valori dei punteggi assegnati ad ogni predizione\n",
        "# label_pred trattiene le predizion delle classi\n",
        "detection_box = [];\n",
        "scores = [];\n",
        "label_pred = [];\n",
        "DETECTION_THRESHOLD = 0.3\n",
        "import os\n",
        "\n",
        "# Raccogli i dati iterando la cartella test\n",
        "for filename in sorted(os.listdir('/content/test/images/')):\n",
        "    print(filename)\n",
        "    path = '/content/test/images/'+filename\n",
        "    detection_result_image,bb,score,classL = run_odt_and_draw_results(\n",
        "      path,\n",
        "      interpreter,\n",
        "      threshold=DETECTION_THRESHOLD)\n",
        "    detection_box.append(bb)\n",
        "    scores.append(score)\n",
        "    label_pred.append(classL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EalanYnZJyV"
      },
      "source": [
        "!mv /content/images/ /content/test/\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ovYmb25NIrv"
      },
      "source": [
        "# Non considero i Tn in quanto utilizzo immagini dove è sempre presente l'immagine di interesse\n",
        "# Effettua il controllo per ogni singola immagine e la classifica come tp,fp,fn\n",
        "THRESHOLD = 0.5\n",
        "SCORETHRESOLD = 0.5\n",
        "tp = 0;\n",
        "fp = 0;\n",
        "fn = 0;\n",
        "tn = 0;\n",
        "for i in range(100):\n",
        "  lunghezza = range(len(detection_box[i]))\n",
        "  \n",
        "  for j in lunghezza:\n",
        "    iOU = compute_iou(detection_box[i][j][0],detection_box[i][j][1],detection_box[i][j][2],detection_box[i][j][3],\n",
        "                    groundtruth_box[i][0],groundtruth_box[i][1],groundtruth_box[i][2],groundtruth_box[i][3])\n",
        "  \n",
        "  if iOU > THRESHOLD and scores[i][0] > SCORETHRESOLD and label_pred[i][j] == label_truth[i]: \n",
        "      tp = tp + 1\n",
        "  elif iOU > THRESHOLD and scores[i][0] > SCORETHRESOLD and label_pred[i][j] != label_truth[i]:\n",
        "      fn = fn +1\n",
        "  elif iOU < THRESHOLD:\n",
        "      fp = fp +1\n",
        "      k = i"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ckSGOp4kVxe",
        "outputId": "3097f4e8-5d89-48dd-caa2-1dac7a6e88d3"
      },
      "source": [
        "print(tp)\n",
        "print(fp)\n",
        "print(fn)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98\n",
            "1\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eubllwpnej4",
        "outputId": "e30de1e6-1099-45f8-99f2-8c91498e7c3c"
      },
      "source": [
        "# PARAMETRI PRESTAZIONALI\n",
        "specificity = tn/(tn + fp)\n",
        "sensitivity = tp/(tp + fn)\n",
        "precision = tp/(tp + fp)\n",
        "\n",
        "print('La specificità è: ', specificity)\n",
        "print('La precisione è: ', precision)\n",
        "print('La sensitività è: ' , sensitivity)\n"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La specificità è:  0.0\n",
            "La precisione è:  0.98989898989899\n",
            "La sensitività è:  0.98989898989899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "pPr98KU42IYQ",
        "outputId": "3b6ae572-e185-48b7-ca3f-e49dd9a96da2"
      },
      "source": [
        "# MATRICE DI CONUSIONE\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "matrix = np.matrix([[98, 1],[1, 0]])\n",
        "ax.matshow(matrix)\n",
        "\n",
        "\n",
        "ax.text(0, 0, tp, va='center', ha='center')\n",
        "ax.text(0, 1, fp, va='center', ha='center')\n",
        "ax.text(1, 0, fn, va='center', ha='center')\n",
        "ax.text(1, 1, tn, va='center', ha='center')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 540x252 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nON97CJ2cY7Z"
      },
      "source": [
        "rm -r /content/train"
      ],
      "execution_count": 128,
      "outputs": []
    }
  ]
}